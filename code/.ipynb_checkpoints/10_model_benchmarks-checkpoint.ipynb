{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Benchmarks\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries And Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Modelling libraries\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Popular boosting package, separate from `sklearn`. (Many Kaggle competitions have been won with `XGBoost`.)\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Modelling using neural networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `preprocessed.csv` from `data` folder into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4969 entries, 0 to 4968\n",
      "Columns: 172 entries, security to sector_Wireless Telecommunication Services\n",
      "dtypes: float64(34), int64(137), object(1)\n",
      "memory usage: 6.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up `X` And `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'cap'\n",
    "X = df[[f for f in df.columns if f not in target and f != 'security' and f != 'year']]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to:\n",
    "- avoid overfitting in our model, and\n",
    "- to get an unbiased estimate of model performance on new, 'unseen' data.\n",
    "\n",
    "We always want to have a holdout set to test our model. Use the `train_test_split` function to split our X and y variables into a training set and a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline will consist of two stages:\n",
    "\n",
    "1. An instance of `StandardScaler`\n",
    "2. A classifier instance\n",
    "\n",
    "Since we want to tune over the classifiers, so we'll load our pipeline object into `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "best_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(\n",
    "    estimator,\n",
    "    param_distributions, \n",
    "    pca=False,\n",
    "    nn=False,\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    y_test=y_test\n",
    "):\n",
    "    steps = [\n",
    "        # Use an instance of `StandardScaler` to scale `X_train` and `X_test` for any model that uses Gradient Descent\n",
    "        ('ss', StandardScaler()), \n",
    "        ('clf', estimator)\n",
    "    ]\n",
    "    if pca:\n",
    "        steps.insert(1, ('pca', PCA()))\n",
    "        if not nn:\n",
    "            param_distributions['pca__n_components'] = np.linspace(0.1, 0.9)\n",
    "    if nn:\n",
    "        # Since this is a multiclass classification problem, keras needs y to be a one-hot encoded matrix.\n",
    "        y_train = pd.get_dummies(y_train)\n",
    "        \n",
    "    # Fit the models on training data\n",
    "    model = RandomizedSearchCV(\n",
    "        estimator=Pipeline(steps),\n",
    "        param_distributions=param_distributions,\n",
    "        n_jobs=-1,\n",
    "        cv=5,\n",
    "        verbose=1\n",
    "    ).fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate models on test data\n",
    "    print(\"Best Combination Of Hyperparameters:\", model.best_params_) \n",
    "    print(\"Best Accuracy:\", model.best_score_)\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            model.predict(X_test), \n",
    "            target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "        )\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.3min finished\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__solver': 'lbfgs', 'clf__penalty': 'none', 'clf__class_weight': None, 'clf__C': 1.9306977288832496}\n",
      "Best Accuracy: 0.8588298443370908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.74      0.63      0.68       316\n",
      "   small-cap       0.76      0.85      0.80       447\n",
      "\n",
      "    accuracy                           0.85      1243\n",
      "   macro avg       0.84      0.82      0.83      1243\n",
      "weighted avg       0.85      0.85      0.85      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    LogisticRegression(max_iter=10_000, multi_class='multinomial'), \n",
    "    {\n",
    "        'clf__penalty': ['l2', 'none'],\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__class_weight': None, 'clf__C': 100.0}\n",
      "Best Accuracy: 0.8548040794417606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       480\n",
      "     mid-cap       0.74      0.61      0.67       316\n",
      "   small-cap       0.75      0.85      0.80       447\n",
      "\n",
      "    accuracy                           0.85      1243\n",
      "   macro avg       0.83      0.82      0.82      1243\n",
      "weighted avg       0.85      0.85      0.84      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    LogisticRegression(penalty='l1', solver='saga', max_iter=10_000, multi_class='multinomial'), \n",
    "    {\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 14.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__l1_ratio': 0.6142857142857143, 'clf__class_weight': None, 'clf__C': 5.179474679231202}\n",
      "Best Accuracy: 0.855072463768116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.73      0.61      0.67       316\n",
      "   small-cap       0.75      0.84      0.80       447\n",
      "\n",
      "    accuracy                           0.84      1243\n",
      "   macro avg       0.83      0.82      0.82      1243\n",
      "weighted avg       0.84      0.84      0.84      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10_000, multi_class='multinomial'), \n",
    "    {\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__l1_ratio': np.linspace(0.1, 1)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   15.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__weights': 'distance', 'clf__n_neighbors': 5, 'clf__metric': 'euclidean'}\n",
      "Best Accuracy: 0.8961352657004831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.87      0.76      0.81       316\n",
      "   small-cap       0.84      0.92      0.88       447\n",
      "\n",
      "    accuracy                           0.91      1243\n",
      "   macro avg       0.90      0.89      0.90      1243\n",
      "weighted avg       0.91      0.91      0.91      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    KNeighborsClassifier(), \n",
    "    {\n",
    "        'clf__n_neighbors': np.arange(1, 22, 2), \n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean','manhattan']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__alpha': 0.0001}\n",
      "Best Accuracy: 0.78341384863124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.95      0.97       480\n",
      "     mid-cap       0.62      0.58      0.60       316\n",
      "   small-cap       0.72      0.79      0.75       447\n",
      "\n",
      "    accuracy                           0.80      1243\n",
      "   macro avg       0.78      0.77      0.77      1243\n",
      "weighted avg       0.80      0.80      0.80      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    BernoulliNB(), \n",
    "    {\n",
    "        'clf__alpha': np.logspace(-5, 2)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Combination Of Hyperparameters: {'clf__var_smoothing': 7.906043210907701e-05}\n",
      "Best Accuracy: 0.8215244229736983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.65      0.70      0.68       316\n",
      "   small-cap       0.78      0.74      0.76       447\n",
      "\n",
      "    accuracy                           0.83      1243\n",
      "   macro avg       0.81      0.81      0.81      1243\n",
      "weighted avg       0.83      0.83      0.83      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    GaussianNB(), \n",
    "    {\n",
    "        'clf__var_smoothing': np.logspace(-9, -4)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "Best Combination Of Hyperparameters: {'clf__min_samples_split': 6, 'clf__min_samples_leaf': 6, 'clf__max_depth': None, 'clf__class_weight': None}\n",
      "Best Accuracy: 0.8099838969404187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.92      0.95      0.94       480\n",
      "     mid-cap       0.72      0.68      0.70       316\n",
      "   small-cap       0.80      0.80      0.80       447\n",
      "\n",
      "    accuracy                           0.83      1243\n",
      "   macro avg       0.81      0.81      0.81      1243\n",
      "weighted avg       0.83      0.83      0.83      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.6s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    DecisionTreeClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 101, 'clf__base_estimator__min_samples_split': 10, 'clf__base_estimator__min_samples_leaf': 2, 'clf__base_estimator__max_depth': None, 'clf__base_estimator__class_weight': None}\n",
      "Best Accuracy: 0.8939881910896403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.97      0.96      0.97       480\n",
      "     mid-cap       0.81      0.84      0.82       316\n",
      "   small-cap       0.88      0.88      0.88       447\n",
      "\n",
      "    accuracy                           0.90      1243\n",
      "   macro avg       0.89      0.89      0.89      1243\n",
      "weighted avg       0.90      0.90      0.90      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    BaggingClassifier(DecisionTreeClassifier()), \n",
    "    {\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 102, 'clf__min_samples_split': 9, 'clf__min_samples_leaf': 1, 'clf__max_depth': 4, 'clf__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.773215244229737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.94      0.87      0.90       480\n",
      "     mid-cap       0.57      0.68      0.62       316\n",
      "   small-cap       0.79      0.75      0.77       447\n",
      "\n",
      "    accuracy                           0.78      1243\n",
      "   macro avg       0.77      0.77      0.77      1243\n",
      "weighted avg       0.80      0.78      0.79      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    RandomForestClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 75, 'clf__min_samples_split': 11, 'clf__min_samples_leaf': 6, 'clf__max_depth': 4, 'clf__class_weight': 'balanced_subsample'}\n",
      "Best Accuracy: 0.7541599570585078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.95      0.99      0.97       480\n",
      "     mid-cap       0.54      0.89      0.67       316\n",
      "   small-cap       0.86      0.42      0.56       447\n",
      "\n",
      "    accuracy                           0.76      1243\n",
      "   macro avg       0.78      0.77      0.73      1243\n",
      "weighted avg       0.81      0.76      0.75      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.9s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    ExtraTreesClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   38.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 133, 'clf__learning_rate': 0.5040816326530613, 'clf__base_estimator__min_samples_split': 5, 'clf__base_estimator__min_samples_leaf': 1, 'clf__base_estimator__max_depth': 2, 'clf__base_estimator__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.8832528180354268\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.77      0.77      0.77       316\n",
      "   small-cap       0.84      0.83      0.84       447\n",
      "\n",
      "    accuracy                           0.88      1243\n",
      "   macro avg       0.87      0.87      0.87      1243\n",
      "weighted avg       0.88      0.88      0.88      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    AdaBoostClassifier(base_estimator=DecisionTreeClassifier()), \n",
    "    {\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 89, 'clf__min_samples_split': 3, 'clf__min_samples_leaf': 2, 'clf__max_depth': 4, 'clf__learning_rate': 0.43061224489795924}\n",
      "Best Accuracy: 0.9439076757917337\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.91      0.90      0.90       316\n",
      "   small-cap       0.93      0.94      0.93       447\n",
      "\n",
      "    accuracy                           0.95      1243\n",
      "   macro avg       0.95      0.94      0.95      1243\n",
      "weighted avg       0.95      0.95      0.95      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    GradientBoostingClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__tree__min_samples_split': 7, 'clf__tree__min_samples_leaf': 6, 'clf__tree__max_depth': 3, 'clf__tree__class_weight': None, 'clf__gb__n_estimators': 117, 'clf__gb__min_samples_split': 15, 'clf__gb__min_samples_leaf': 1, 'clf__gb__max_depth': 2, 'clf__gb__learning_rate': 0.48571428571428577, 'clf__ada__n_estimators': 32, 'clf__ada__learning_rate': 0.7061224489795919, 'clf__ada__base_estimator__min_samples_split': 19, 'clf__ada__base_estimator__min_samples_leaf': 3, 'clf__ada__base_estimator__max_depth': None, 'clf__ada__base_estimator__class_weight': None}\n",
      "Best Accuracy: 0.9079441760601181\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.98      0.98      0.98       480\n",
      "     mid-cap       0.83      0.85      0.84       316\n",
      "   small-cap       0.90      0.89      0.90       447\n",
      "\n",
      "    accuracy                           0.91      1243\n",
      "   macro avg       0.91      0.91      0.91      1243\n",
      "weighted avg       0.92      0.91      0.92      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    VotingClassifier([\n",
    "        ('tree', DecisionTreeClassifier()), \n",
    "        ('ada', AdaBoostClassifier(base_estimator=DecisionTreeClassifier())), \n",
    "        ('gb', GradientBoostingClassifier())\n",
    "    ]), \n",
    "    {\n",
    "        'clf__tree__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__tree__min_samples_split': np.arange(2, 21),\n",
    "        'clf__tree__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__tree__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__ada__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__ada__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__ada__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__n_estimators': np.arange(1, 150), \n",
    "        'clf__ada__learning_rate': np.linspace(0.1, 1),\n",
    "        'clf__gb__max_depth': np.arange(1, 5),\n",
    "        'clf__gb__n_estimators': np.arange(1, 150), \n",
    "        'clf__gb__min_samples_split': np.arange(2, 21),\n",
    "        'clf__gb__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__gb__learning_rate': np.linspace(0.1, 1)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 616, 'clf__max_depth': 12, 'clf__learning_rate': 0.3938775510204082}\n",
      "Best Accuracy: 0.9452495974235104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      0.99       480\n",
      "     mid-cap       0.93      0.91      0.92       316\n",
      "   small-cap       0.93      0.95      0.94       447\n",
      "\n",
      "    accuracy                           0.95      1243\n",
      "   macro avg       0.95      0.95      0.95      1243\n",
      "weighted avg       0.95      0.95      0.95      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    XGBClassifier(objective='multi:softprob'), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 25),\n",
    "        'clf__n_estimators': np.arange(1, 1000), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   58.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__kernel': 'poly', 'clf__gamma': 1.9306977288832496, 'clf__class_weight': 'balanced', 'clf__C': 0.7196856730011514}\n",
      "Best Accuracy: 0.8939881910896403\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.83      0.79      0.81       316\n",
      "   small-cap       0.86      0.89      0.87       447\n",
      "\n",
      "    accuracy                           0.91      1243\n",
      "   macro avg       0.90      0.89      0.89      1243\n",
      "weighted avg       0.91      0.91      0.91      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    SVC(decision_function_shape='ovo'), \n",
    "    {\n",
    "        'clf__C': np.logspace(-5, 2),\n",
    "        'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'clf__gamma': list(np.logspace(-5, 2)) + ['scale'],\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    }\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.561224 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.591837 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Best Combination Of Hyperparameters: {'clf__opt_learning_rate': 0.0029470517025518097, 'clf__layer_two_neurons': 162, 'clf__layer_two_dropout': 0.5918367346938775, 'clf__layer_one_neurons': 30, 'clf__layer_one_dropout': 0.5612244897959183, 'clf__epochs': 37, 'clf__batch_size': 128}\n",
      "Best Accuracy: 0.8247450452239937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.64      0.67      0.66       316\n",
      "   small-cap       0.76      0.73      0.74       447\n",
      "\n",
      "    accuracy                           0.82      1243\n",
      "   macro avg       0.80      0.80      0.80      1243\n",
      "weighted avg       0.82      0.82      0.82      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def ffnn_fn(\n",
    "    layer_one_neurons=18,\n",
    "    layer_two_neurons=18,\n",
    "    layer_one_dropout=0.5,\n",
    "    layer_two_dropout=0.5,\n",
    "    opt_learning_rate=0.01\n",
    "):\n",
    "    # Create a neural network using the Dense and Dropout layers from keras. \n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_one_neurons, activation='relu', kernel_regularizer=l2(), input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(layer_one_dropout))\n",
    "    model.add(Dense(layer_two_neurons, activation='relu', kernel_regularizer=l2()))\n",
    "    model.add(Dropout(layer_two_dropout))\n",
    "    \n",
    "    # Activation function for the final output layer needs to be softmax \n",
    "    # to accomidate the three different classes.\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    ad = Adam(learning_rate=opt_learning_rate)\n",
    "    \n",
    "    # Compile model\n",
    "    # Since this is a multiclass classification problem,loss function is categorical_crossentropy.\n",
    "    model.compile(optimizer=ad, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = fit_model(\n",
    "    KerasClassifier(build_fn=ffnn_fn, verbose=0), \n",
    "    {\n",
    "        'clf__layer_one_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_two_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_one_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__layer_two_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__opt_learning_rate': np.logspace(-4, -1),\n",
    "        'clf__batch_size': [128, 256],\n",
    "        'clf__epochs': np.arange(5, 50)\n",
    "    },\n",
    "    nn=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling With `PCA`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `PCA` (Principal component analysis) to simplify data, reduce noise, and find unmeasured latent variables.\n",
    "\n",
    "Our pipeline will consist of three stages:\n",
    "\n",
    "1. An instance of `StandardScaler`\n",
    "2. An instance of `PCA`\n",
    "3. A classifier instance\n",
    "\n",
    "Since we want to tune over the classifiers, so we'll load our pipeline object into `RandomizedSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.8min finished\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.6224489795918368, 'clf__solver': 'sag', 'clf__penalty': 'none', 'clf__class_weight': None, 'clf__C': 5.1794746792312125e-05}\n",
      "Best Accuracy: 0.8467525496511004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.99      1.00      1.00       480\n",
      "     mid-cap       0.74      0.61      0.67       316\n",
      "   small-cap       0.76      0.85      0.80       447\n",
      "\n",
      "    accuracy                           0.85      1243\n",
      "   macro avg       0.83      0.82      0.82      1243\n",
      "weighted avg       0.84      0.85      0.84      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    LogisticRegression(max_iter=10_000, multi_class='multinomial'), \n",
    "    {\n",
    "        'clf__penalty': ['l2', 'none'],\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.8836734693877552, 'clf__class_weight': 'balanced', 'clf__C': 0.7196856730011514}\n",
      "Best Accuracy: 0.8462157809983897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.69      0.75      0.72       316\n",
      "   small-cap       0.82      0.77      0.79       447\n",
      "\n",
      "    accuracy                           0.85      1243\n",
      "   macro avg       0.84      0.84      0.84      1243\n",
      "weighted avg       0.85      0.85      0.85      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    LogisticRegression(penalty='l1', solver='saga', max_iter=10_000, multi_class='multinomial'), \n",
    "    {\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   35.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.7857142857142857, 'clf__l1_ratio': 0.17346938775510207, 'clf__class_weight': None, 'clf__C': 0.05179474679231207}\n",
      "Best Accuracy: 0.8298443370907139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.99      1.00      0.99       480\n",
      "     mid-cap       0.70      0.56      0.63       316\n",
      "   small-cap       0.73      0.83      0.78       447\n",
      "\n",
      "    accuracy                           0.83      1243\n",
      "   macro avg       0.81      0.80      0.80      1243\n",
      "weighted avg       0.82      0.83      0.82      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10_000, multi_class='multinomial'), \n",
    "    {\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__l1_ratio': np.linspace(0.1, 1)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.8346938775510204, 'clf__weights': 'distance', 'clf__n_neighbors': 1, 'clf__metric': 'euclidean'}\n",
      "Best Accuracy: 0.9133118625872249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       480\n",
      "     mid-cap       0.84      0.81      0.83       316\n",
      "   small-cap       0.87      0.89      0.88       447\n",
      "\n",
      "    accuracy                           0.91      1243\n",
      "   macro avg       0.90      0.90      0.90      1243\n",
      "weighted avg       0.91      0.91      0.91      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    KNeighborsClassifier(), \n",
    "    {\n",
    "        'clf__n_neighbors': np.arange(1, 22, 2), \n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean','manhattan']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.589795918367347, 'clf__alpha': 0.003727593720314938}\n",
      "Best Accuracy: 0.7106816961889426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.85      1.00      0.92       480\n",
      "     mid-cap       0.53      0.70      0.61       316\n",
      "   small-cap       0.77      0.45      0.57       447\n",
      "\n",
      "    accuracy                           0.73      1243\n",
      "   macro avg       0.72      0.72      0.70      1243\n",
      "weighted avg       0.74      0.73      0.71      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    BernoulliNB(), \n",
    "    {\n",
    "        'clf__alpha': np.logspace(-5, 2)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.4591836734693878, 'clf__var_smoothing': 3.5564803062231287e-07}\n",
      "Best Accuracy: 0.7283950617283951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.91      1.00      0.95       480\n",
      "     mid-cap       0.53      0.88      0.66       316\n",
      "   small-cap       0.90      0.38      0.54       447\n",
      "\n",
      "    accuracy                           0.75      1243\n",
      "   macro avg       0.78      0.75      0.72      1243\n",
      "weighted avg       0.81      0.75      0.73      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.3s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    GaussianNB(), \n",
    "    {\n",
    "        'clf__var_smoothing': np.logspace(-9, -4)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.2469387755102041, 'clf__min_samples_split': 6, 'clf__min_samples_leaf': 5, 'clf__max_depth': None, 'clf__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.8193773483628556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.99      0.96      0.97       480\n",
      "     mid-cap       0.67      0.71      0.69       316\n",
      "   small-cap       0.78      0.77      0.77       447\n",
      "\n",
      "    accuracy                           0.83      1243\n",
      "   macro avg       0.81      0.81      0.81      1243\n",
      "weighted avg       0.83      0.83      0.83      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    4.7s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    DecisionTreeClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.8020408163265307, 'clf__n_estimators': 60, 'clf__base_estimator__min_samples_split': 4, 'clf__base_estimator__min_samples_leaf': 2, 'clf__base_estimator__max_depth': None, 'clf__base_estimator__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.9001610305958132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.82      0.79      0.81       316\n",
      "   small-cap       0.86      0.88      0.87       447\n",
      "\n",
      "    accuracy                           0.90      1243\n",
      "   macro avg       0.89      0.89      0.89      1243\n",
      "weighted avg       0.90      0.90      0.90      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    BaggingClassifier(DecisionTreeClassifier()), \n",
    "    {\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.7693877551020408, 'clf__n_estimators': 131, 'clf__min_samples_split': 3, 'clf__min_samples_leaf': 6, 'clf__max_depth': 3, 'clf__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.8215244229736983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.98      1.00      0.99       480\n",
      "     mid-cap       0.63      0.77      0.69       316\n",
      "   small-cap       0.80      0.66      0.72       447\n",
      "\n",
      "    accuracy                           0.82      1243\n",
      "   macro avg       0.81      0.81      0.80      1243\n",
      "weighted avg       0.83      0.82      0.82      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    RandomForestClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.4755102040816327, 'clf__n_estimators': 34, 'clf__min_samples_split': 19, 'clf__min_samples_leaf': 6, 'clf__max_depth': 4, 'clf__class_weight': 'balanced_subsample'}\n",
      "Best Accuracy: 0.7659688674181427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.98      0.99      0.99       480\n",
      "     mid-cap       0.53      0.94      0.68       316\n",
      "   small-cap       0.91      0.41      0.57       447\n",
      "\n",
      "    accuracy                           0.77      1243\n",
      "   macro avg       0.81      0.78      0.75      1243\n",
      "weighted avg       0.84      0.77      0.76      1243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.0s finished\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    ExtraTreesClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.5408163265306123, 'clf__n_estimators': 100, 'clf__learning_rate': 0.8530612244897959, 'clf__base_estimator__min_samples_split': 18, 'clf__base_estimator__min_samples_leaf': 7, 'clf__base_estimator__max_depth': None, 'clf__base_estimator__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.9114331723027376\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.85      0.80      0.82       316\n",
      "   small-cap       0.86      0.90      0.88       447\n",
      "\n",
      "    accuracy                           0.91      1243\n",
      "   macro avg       0.90      0.90      0.90      1243\n",
      "weighted avg       0.91      0.91      0.91      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    AdaBoostClassifier(base_estimator=DecisionTreeClassifier()), \n",
    "    {\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   37.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   41.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.5571428571428572, 'clf__n_estimators': 106, 'clf__min_samples_split': 18, 'clf__min_samples_leaf': 7, 'clf__max_depth': 4, 'clf__learning_rate': 0.41224489795918373}\n",
      "Best Accuracy: 0.8918411164787976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.83      0.77      0.80       316\n",
      "   small-cap       0.85      0.89      0.87       447\n",
      "\n",
      "    accuracy                           0.90      1243\n",
      "   macro avg       0.89      0.89      0.89      1243\n",
      "weighted avg       0.90      0.90      0.90      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    GradientBoostingClassifier(), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.6061224489795919, 'clf__tree__min_samples_split': 16, 'clf__tree__min_samples_leaf': 7, 'clf__tree__max_depth': 4, 'clf__tree__class_weight': None, 'clf__gb__n_estimators': 18, 'clf__gb__min_samples_split': 10, 'clf__gb__min_samples_leaf': 4, 'clf__gb__max_depth': 4, 'clf__gb__learning_rate': 0.6142857142857143, 'clf__ada__n_estimators': 88, 'clf__ada__learning_rate': 0.11836734693877551, 'clf__ada__base_estimator__min_samples_split': 13, 'clf__ada__base_estimator__min_samples_leaf': 7, 'clf__ada__base_estimator__max_depth': None, 'clf__ada__base_estimator__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.8918411164787976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.84      0.77      0.80       316\n",
      "   small-cap       0.85      0.89      0.87       447\n",
      "\n",
      "    accuracy                           0.90      1243\n",
      "   macro avg       0.89      0.89      0.89      1243\n",
      "weighted avg       0.90      0.90      0.90      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    VotingClassifier([\n",
    "        ('tree', DecisionTreeClassifier()), \n",
    "        ('ada', AdaBoostClassifier(base_estimator=DecisionTreeClassifier())), \n",
    "        ('gb', GradientBoostingClassifier())\n",
    "    ]), \n",
    "    {\n",
    "        'clf__tree__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__tree__min_samples_split': np.arange(2, 21),\n",
    "        'clf__tree__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__tree__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__ada__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__ada__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__ada__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__n_estimators': np.arange(1, 150), \n",
    "        'clf__ada__learning_rate': np.linspace(0.1, 1),\n",
    "        'clf__gb__max_depth': np.arange(1, 5),\n",
    "        'clf__gb__n_estimators': np.arange(1, 150), \n",
    "        'clf__gb__min_samples_split': np.arange(2, 21),\n",
    "        'clf__gb__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__gb__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 10.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.49183673469387756, 'clf__n_estimators': 304, 'clf__max_depth': 21, 'clf__learning_rate': 0.5408163265306123}\n",
      "Best Accuracy: 0.9143853998926462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.85      0.82      0.83       316\n",
      "   small-cap       0.87      0.90      0.89       447\n",
      "\n",
      "    accuracy                           0.92      1243\n",
      "   macro avg       0.91      0.90      0.91      1243\n",
      "weighted avg       0.92      0.92      0.92      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    XGBClassifier(objective='multi:softprob'), \n",
    "    {\n",
    "        'clf__max_depth': np.arange(1, 25),\n",
    "        'clf__n_estimators': np.arange(1, 1000), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'pca__n_components': 0.589795918367347, 'clf__kernel': 'linear', 'clf__gamma': 1.9306977288832496, 'clf__class_weight': 'balanced', 'clf__C': 2.682695795279722}\n",
      "Best Accuracy: 0.8475577026301664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.70      0.75      0.72       316\n",
      "   small-cap       0.81      0.77      0.79       447\n",
      "\n",
      "    accuracy                           0.85      1243\n",
      "   macro avg       0.84      0.84      0.84      1243\n",
      "weighted avg       0.86      0.85      0.85      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    SVC(decision_function_shape='ovo'), \n",
    "    {\n",
    "        'clf__C': np.logspace(-5, 2),\n",
    "        'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'clf__gamma': list(np.logspace(-5, 2)) + ['scale'],\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    pca=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.714286 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.702041 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__opt_learning_rate': 0.0019306977288832496, 'clf__layer_two_neurons': 134, 'clf__layer_two_dropout': 0.7020408163265306, 'clf__layer_one_neurons': 113, 'clf__layer_one_dropout': 0.7142857142857143, 'clf__epochs': 22, 'clf__batch_size': 128}\n",
      "Best Accuracy: 0.8177670447882694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       480\n",
      "     mid-cap       0.62      0.75      0.68       316\n",
      "   small-cap       0.80      0.68      0.73       447\n",
      "\n",
      "    accuracy                           0.82      1243\n",
      "   macro avg       0.81      0.81      0.81      1243\n",
      "weighted avg       0.83      0.82      0.82      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = fit_model(\n",
    "    KerasClassifier(build_fn=ffnn_fn, verbose=0), \n",
    "    {\n",
    "        'clf__layer_one_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_two_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_one_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__layer_two_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__opt_learning_rate': np.logspace(-4, -1),\n",
    "        'clf__batch_size': [128, 256],\n",
    "        'clf__epochs': np.arange(5, 50)\n",
    "    },\n",
    "    pca=True,\n",
    "    nn=True\n",
    ")\n",
    "models.append(model)\n",
    "best_scores.append(model.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bytree=1, gamma=0, learning_rate=0.3938775510204082,\n",
       "              max_delta_step=0, max_depth=12, min_child_weight=1, missing=None,\n",
       "              n_estimators=616, n_jobs=1, nthread=None,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "              subsample=1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[best_scores.index(max(best_scores))]\n",
    "best_model.best_estimator_.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.9452495974235104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      0.99       480\n",
      "     mid-cap       0.93      0.91      0.92       316\n",
      "   small-cap       0.93      0.95      0.94       447\n",
      "\n",
      "    accuracy                           0.95      1243\n",
      "   macro avg       0.95      0.95      0.95      1243\n",
      "weighted avg       0.95      0.95      0.95      1243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy:\", best_model.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        best_model.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model is one that overfits the least and has the best training and test accuracies. In this case, `XGBClassifier` has a training and test accuracies of 0.95, which makes it the best performing model.\n",
    "\n",
    "Comparing with [baseline accuracy of 0.39](09_preprocessing_and_feature_engineering.ipynb#Baseline-Accuracy), `XGBClassifier` has higher accuracies than baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export To `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(best_model.predict(X)).to_csv('../data/predict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Features': X.columns, \n",
    "    'Feature Importance': best_model.best_estimator_.named_steps['clf'].feature_importances_\n",
    "}).sort_values('Feature Importance', ascending=False).to_csv('../data/feature_importance.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
