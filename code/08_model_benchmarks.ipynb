{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project Part 08: Model Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `preprocessed.csv` from `data` folder into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3452 entries, 0 to 3451\n",
      "Columns: 171 entries, year to sector_Wireless Telecommunication Services\n",
      "dtypes: float64(37), int64(133), object(1)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/preprocessed.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'cap'\n",
    "X = df[[f for f in df.columns if f not in target and f != 'security' and f != 'year']]\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', LogisticRegression(max_iter=10_000, multi_class='multinomial'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__penalty': ['l2', 'none'],\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_l1 = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', LogisticRegression(penalty='l1', solver='saga', max_iter=10_000, multi_class='multinomial'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_elasticnet = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10_000, multi_class='multinomial'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__l1_ratio': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__n_neighbors': np.arange(1, 22, 2), \n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean','manhattan']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', BernoulliNB())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__alpha': np.logspace(-5, 2)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', GaussianNB())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__var_smoothing': np.logspace(-9, -4)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', BaggingClassifier(DecisionTreeClassifier()))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', RandomForestClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', ExtraTreesClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', VotingClassifier([\n",
    "            ('tree', DecisionTreeClassifier()), \n",
    "            ('ada', AdaBoostClassifier(base_estimator=DecisionTreeClassifier())), \n",
    "            ('gb', GradientBoostingClassifier())\n",
    "        ]))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__tree__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__tree__min_samples_split': np.arange(2, 21),\n",
    "        'clf__tree__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__tree__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__ada__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__ada__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__ada__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__n_estimators': np.arange(1, 150), \n",
    "        'clf__ada__learning_rate': np.linspace(0.1, 1),\n",
    "        'clf__gb__max_depth': np.arange(1, 5),\n",
    "        'clf__gb__n_estimators': np.arange(1, 150), \n",
    "        'clf__gb__min_samples_split': np.arange(2, 21),\n",
    "        'clf__gb__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__gb__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', XGBClassifier(objective='multi:softprob'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__max_depth': np.arange(1, 25),\n",
    "        'clf__n_estimators': np.arange(1, 1000), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', SVC(decision_function_shape='ovo'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__C': np.logspace(-5, 2),\n",
    "        'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'clf__gamma': list(np.logspace(-5, 2)) + ['scale'],\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Since this is a multiclass classification problem, keras needs y to be a one-hot encoded matrix\n",
    "y_train_dummies = pd.get_dummies(y_train)\n",
    "\n",
    "def ffnn_fn(\n",
    "    layer_one_neurons=18,\n",
    "    layer_two_neurons=18,\n",
    "    layer_one_dropout=0.5,\n",
    "    layer_two_dropout=0.5,\n",
    "    opt_learning_rate=0.01\n",
    "):\n",
    "    # Create a neural network using the Dense and Dropout layers from keras. \n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_one_neurons, activation='relu', kernel_regularizer=l2(), input_dim=X_train.shape[1]))\n",
    "    model.add(Dropout(layer_one_dropout))\n",
    "    model.add(Dense(layer_two_neurons, activation='relu', kernel_regularizer=l2()))\n",
    "    model.add(Dropout(layer_two_dropout))\n",
    "    \n",
    "    # Activation function for the final output layer needs to be softmax \n",
    "    # to accomidate the three different classes.\n",
    "    model.add(Dense(y_train_dummies.shape[1], activation='softmax'))\n",
    "    \n",
    "    ad = Adam(learning_rate=opt_learning_rate)\n",
    "    \n",
    "    # Compile model\n",
    "    # Since this is a multiclass classification problem,loss function is categorical_crossentropy.\n",
    "    model.compile(optimizer=ad, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "ffnn = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('clf', KerasClassifier(build_fn=ffnn_fn, verbose=0))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__layer_one_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_two_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_one_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__layer_two_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__opt_learning_rate': np.logspace(-4, -1),\n",
    "        'clf__batch_size': [128, 256],\n",
    "        'clf__epochs': np.arange(5, 50)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  6.6min finished\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=10000,\n",
       "                                                                 multi_class='multinomial',\n",
       "                                                                 n_jobs=None,\n",
       "                                                                 penalty='l2',\n",
       "                                                                 random_state=N...\n",
       "       5.17947468e+00, 7.19685673e+00, 1.00000000e+01, 1.38949549e+01,\n",
       "       1.93069773e+01, 2.68269580e+01, 3.72759372e+01, 5.17947468e+01,\n",
       "       7.19685673e+01, 1.00000000e+02]),\n",
       "                                        'clf__class_weight': [None, 'balanced'],\n",
       "                                        'clf__penalty': ['l2', 'none'],\n",
       "                                        'clf__solver': ['newton-cg', 'sag',\n",
       "                                                        'lbfgs']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=10000,\n",
       "                                                                 multi_class='multinomial',\n",
       "                                                                 n_jobs=None,\n",
       "                                                                 penalty='l1',\n",
       "                                                                 random_state=N...\n",
       "       1.38949549e+00, 1.93069773e+00, 2.68269580e+00, 3.72759372e+00,\n",
       "       5.17947468e+00, 7.19685673e+00, 1.00000000e+01, 1.38949549e+01,\n",
       "       1.93069773e+01, 2.68269580e+01, 3.72759372e+01, 5.17947468e+01,\n",
       "       7.19685673e+01, 1.00000000e+02]),\n",
       "                                        'clf__class_weight': [None,\n",
       "                                                              'balanced']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 11.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 15.8min finished\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept=True,\n",
       "                                                                 intercept_scaling=1,\n",
       "                                                                 l1_ratio=None,\n",
       "                                                                 max_iter=10000,\n",
       "                                                                 multi_class='multinomial',\n",
       "                                                                 n_jobs=None,\n",
       "                                                                 penalty='elasticnet',\n",
       "                                                                 random...\n",
       "       0.55918367, 0.57755102, 0.59591837, 0.61428571, 0.63265306,\n",
       "       0.65102041, 0.66938776, 0.6877551 , 0.70612245, 0.7244898 ,\n",
       "       0.74285714, 0.76122449, 0.77959184, 0.79795918, 0.81632653,\n",
       "       0.83469388, 0.85306122, 0.87142857, 0.88979592, 0.90816327,\n",
       "       0.92653061, 0.94489796, 0.96326531, 0.98163265, 1.        ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_elasticnet.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                                   leaf_size=30,\n",
       "                                                                   metric='minkowski',\n",
       "                                                                   metric_params=None,\n",
       "                                                                   n_jobs=None,\n",
       "                                                                   n_neighbors=5,\n",
       "                                                                   p=2,\n",
       "                                                                   weights='uniform'))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__metric': ['euclidean',\n",
       "                                                        'manhattan'],\n",
       "                                        'clf__n_neighbors': array([ 1,  3,  5,  7,  9, 11, 13, 15, 17, 19, 21]),\n",
       "                                        'clf__weights': ['uniform',\n",
       "                                                         'distance']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              BernoulliNB(alpha=1.0,\n",
       "                                                          binarize=0.0,\n",
       "                                                          class_prior=None,\n",
       "                                                          fit_prior=True))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__alpha': array([1.00000000e-05, 1.38949549e-05,...\n",
       "       3.72759372e-01, 5.17947468e-01, 7.19685673e-01, 1.00000000e+00,\n",
       "       1.38949549e+00, 1.93069773e+00, 2.68269580e+00, 3.72759372e+00,\n",
       "       5.17947468e+00, 7.19685673e+00, 1.00000000e+01, 1.38949549e+01,\n",
       "       1.93069773e+01, 2.68269580e+01, 3.72759372e+01, 5.17947468e+01,\n",
       "       7.19685673e+01, 1.00000000e+02])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              GaussianNB(priors=None,\n",
       "                                                         var_smoothing=1e-09))],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__var_smoothing': array([1.00000000e-09, 1.26485522e-09, 1.59985872e-09, 2...\n",
       "       1.84206997e-06, 2.32995181e-06, 2.94705170e-06, 3.72759372e-06,\n",
       "       4.71486636e-06, 5.96362332e-06, 7.54312006e-06, 9.54095476e-06,\n",
       "       1.20679264e-05, 1.52641797e-05, 1.93069773e-05, 2.44205309e-05,\n",
       "       3.08884360e-05, 3.90693994e-05, 4.94171336e-05, 6.25055193e-05,\n",
       "       7.90604321e-05, 1.00000000e-04])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features=None,\n",
       "                                                                     max_leaf_nodes=None,\n",
       "                                                                     min_impurity_decrease=0.0,\n",
       "                                                                     min_impurity_split=None,\n",
       "                                                                     min_samples_leaf=1,\n",
       "                                                                     min_sam...\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__class_weight': [None, 'balanced'],\n",
       "                                        'clf__max_depth': [1, 2, 3, 4, None],\n",
       "                                        'clf__min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        'clf__min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   40.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                                      criterion='gini',\n",
       "                                                                                                      max_depth=None,\n",
       "                                                                                                      max_features=None,\n",
       "                                                                                                      max_leaf_nodes=None,\n",
       "                                                                                                      min_impurity_decrease=0.0,\n",
       "                                                                                                      min_impurity_spli...\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagged.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              RandomForestClassifier(bootstrap=True,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth=None,\n",
       "                                                                     max_features='auto',\n",
       "                                                                     max_leaf_nodes=None,\n",
       "                                                                     min_impurity_decrease=0.0,\n",
       "                                                                     min_impurity_split=None,\n",
       "                                                                     min_sampl...\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              ExtraTreesClassifier(bootstrap=False,\n",
       "                                                                   class_weight=None,\n",
       "                                                                   criterion='gini',\n",
       "                                                                   max_depth=None,\n",
       "                                                                   max_features='auto',\n",
       "                                                                   max_leaf_nodes=None,\n",
       "                                                                   min_impurity_decrease=0.0,\n",
       "                                                                   min_impurity_split=None,\n",
       "                                                                   min_sample...\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   42.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                 base_estimator=DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                                       criterion='gini',\n",
       "                                                                                                       max_depth=None,\n",
       "                                                                                                       max_features=None,\n",
       "                                                                                                       max_leaf_nodes=None,\n",
       "                                                                                                       min_impurity_decrease=...\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   41.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                         init=None,\n",
       "                                                                         learning_rate=0.1,\n",
       "                                                                         loss='deviance',\n",
       "                                                                         max_depth=3,\n",
       "                                                                         max_features=None,\n",
       "                                                                         max_leaf_nodes=None,\n",
       "                                                                         min_impurity_decrease=0.0,\n",
       "                                                                         min_impurity_sp...\n",
       "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "        92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
       "       105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117,\n",
       "       118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130,\n",
       "       131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143,\n",
       "       144, 145, 146, 147, 148, 149])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              VotingClassifier(estimators=[('tree',\n",
       "                                                                            DecisionTreeClassifier(class_weight=None,\n",
       "                                                                                                   criterion='gini',\n",
       "                                                                                                   max_depth=None,\n",
       "                                                                                                   max_features=None,\n",
       "                                                                                                   max_leaf_nodes=None,\n",
       "                                                                                                   min_impurity_decrease=0.0,\n",
       "                                                                                                   min_impurity_...\n",
       "       144, 145, 146, 147, 148, 149]),\n",
       "                                        'clf__tree__class_weight': [None,\n",
       "                                                                    'balanced'],\n",
       "                                        'clf__tree__max_depth': [1, 2, 3, 4,\n",
       "                                                                 None],\n",
       "                                        'clf__tree__min_samples_leaf': array([1, 2, 3, 4, 5, 6, 7]),\n",
       "                                        'clf__tree__min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 10.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              XGBClassifier(base_score=0.5,\n",
       "                                                            booster='gbtree',\n",
       "                                                            colsample_bylevel=1,\n",
       "                                                            colsample_bytree=1,\n",
       "                                                            gamma=0,\n",
       "                                                            learning_rate=0.1,\n",
       "                                                            max_delta_step=0,\n",
       "                                                            max_depth=3,\n",
       "                                                            min_child_weight=1,\n",
       "                                                            missing=None,\n",
       "                                                            n_estimators=10...\n",
       "       937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949,\n",
       "       950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962,\n",
       "       963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975,\n",
       "       976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988,\n",
       "       989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   32.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              SVC(C=1.0, cache_size=200,\n",
       "                                                  class_weight=None, coef0=0.0,\n",
       "                                                  decision_function_shape='ovo',\n",
       "                                                  degree=3,\n",
       "                                                  gamma='auto_deprecated',\n",
       "                                                  kernel='rbf', max_iter=-1,\n",
       "                                                  probability=False,\n",
       "                                                  random_state=None,\n",
       "                                                  shrinking=...\n",
       "                                                       0.003727593720314938,\n",
       "                                                       0.005179474679231208,\n",
       "                                                       0.007196856730011514,\n",
       "                                                       0.01,\n",
       "                                                       0.013894954943731374,\n",
       "                                                       0.019306977288832496,\n",
       "                                                       0.026826957952797246,\n",
       "                                                       0.03727593720314938,\n",
       "                                                       0.05179474679231207,\n",
       "                                                       0.07196856730011514, 0.1,\n",
       "                                                       0.1389495494373136, ...],\n",
       "                                        'clf__kernel': ['linear', 'poly', 'rbf',\n",
       "                                                        'sigmoid']},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.616327 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.561224 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('clf',\n",
       "                                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x14b944110>)],\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'clf__batch_size': [128, 256],\n",
       "                                        'clf__epochs': array([ 5,  6,...\n",
       "       0.00339322, 0.00390694, 0.00449843, 0.00517947, 0.00596362,\n",
       "       0.00686649, 0.00790604, 0.00910298, 0.01048113, 0.01206793,\n",
       "       0.01389495, 0.01599859, 0.0184207 , 0.02120951, 0.02442053,\n",
       "       0.02811769, 0.03237458, 0.03727594, 0.04291934, 0.04941713,\n",
       "       0.05689866, 0.06551286, 0.0754312 , 0.08685114, 0.1       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn.fit(X_train, y_train_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__solver': 'lbfgs', 'clf__penalty': 'none', 'clf__class_weight': 'balanced', 'clf__C': 10.0}\n",
      "Best Accuracy: 0.9057551178061027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.65      0.74      0.69       151\n",
      "   small-cap       0.82      0.75      0.78       238\n",
      "\n",
      "    accuracy                           0.89       863\n",
      "   macro avg       0.82      0.83      0.82       863\n",
      "weighted avg       0.89      0.89      0.89       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", lr.best_params_) \n",
    "print(\"Best Accuracy:\", lr.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        lr.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__class_weight': 'balanced', 'clf__C': 1.389495494373136}\n",
      "Best Accuracy: 0.8941676322904596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.65      0.76      0.70       151\n",
      "   small-cap       0.83      0.74      0.78       238\n",
      "\n",
      "    accuracy                           0.89       863\n",
      "   macro avg       0.83      0.83      0.83       863\n",
      "weighted avg       0.89      0.89      0.89       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", lr_l1.best_params_) \n",
    "print(\"Best Accuracy:\", lr_l1.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        lr_l1.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__l1_ratio': 0.9081632653061225, 'clf__class_weight': 'balanced', 'clf__C': 5.179474679231202}\n",
      "Best Accuracy: 0.8941676322904596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       474\n",
      "     mid-cap       0.63      0.75      0.69       151\n",
      "   small-cap       0.82      0.73      0.78       238\n",
      "\n",
      "    accuracy                           0.88       863\n",
      "   macro avg       0.82      0.83      0.82       863\n",
      "weighted avg       0.89      0.88      0.88       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", lr_elasticnet.best_params_) \n",
    "print(\"Best Accuracy:\", lr_elasticnet.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        lr_elasticnet.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__weights': 'distance', 'clf__n_neighbors': 7, 'clf__metric': 'manhattan'}\n",
      "Best Accuracy: 0.9235225955967555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       474\n",
      "     mid-cap       0.84      0.81      0.83       151\n",
      "   small-cap       0.88      0.91      0.89       238\n",
      "\n",
      "    accuracy                           0.94       863\n",
      "   macro avg       0.91      0.91      0.91       863\n",
      "weighted avg       0.94      0.94      0.94       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", knn.best_params_) \n",
    "print(\"Best Accuracy:\", knn.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        knn.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__alpha': 1e-05}\n",
      "Best Accuracy: 0.8505214368482039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.58      0.58      0.58       151\n",
      "   small-cap       0.74      0.74      0.74       238\n",
      "\n",
      "    accuracy                           0.85       863\n",
      "   macro avg       0.77      0.77      0.77       863\n",
      "weighted avg       0.85      0.85      0.85       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", bnb.best_params_) \n",
    "print(\"Best Accuracy:\", bnb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        bnb.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__var_smoothing': 7.906043210907701e-05}\n",
      "Best Accuracy: 0.8501351873310158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.65      0.68      0.66       151\n",
      "   small-cap       0.79      0.77      0.78       238\n",
      "\n",
      "    accuracy                           0.88       863\n",
      "   macro avg       0.81      0.81      0.81       863\n",
      "weighted avg       0.88      0.88      0.88       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", gnb.best_params_) \n",
    "print(\"Best Accuracy:\", gnb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        gnb.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__min_samples_split': 7, 'clf__min_samples_leaf': 1, 'clf__max_depth': None, 'clf__class_weight': None}\n",
      "Best Accuracy: 0.8733101583623021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.96      0.97      0.97       474\n",
      "     mid-cap       0.74      0.72      0.73       151\n",
      "   small-cap       0.83      0.84      0.84       238\n",
      "\n",
      "    accuracy                           0.89       863\n",
      "   macro avg       0.85      0.84      0.85       863\n",
      "weighted avg       0.89      0.89      0.89       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", tree.best_params_) \n",
    "print(\"Best Accuracy:\", tree.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        tree.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 85, 'clf__base_estimator__min_samples_split': 13, 'clf__base_estimator__min_samples_leaf': 1, 'clf__base_estimator__max_depth': 4, 'clf__base_estimator__class_weight': None}\n",
      "Best Accuracy: 0.8427964465044419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.93      0.95      0.94       474\n",
      "     mid-cap       0.64      0.54      0.58       151\n",
      "   small-cap       0.78      0.82      0.80       238\n",
      "\n",
      "    accuracy                           0.84       863\n",
      "   macro avg       0.78      0.77      0.77       863\n",
      "weighted avg       0.84      0.84      0.84       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", bagged.best_params_) \n",
    "print(\"Best Accuracy:\", bagged.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        bagged.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 60, 'clf__min_samples_split': 6, 'clf__min_samples_leaf': 7, 'clf__max_depth': 4, 'clf__class_weight': 'balanced_subsample'}\n",
      "Best Accuracy: 0.8091927385090769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.96      0.86      0.91       474\n",
      "     mid-cap       0.45      0.62      0.52       151\n",
      "   small-cap       0.79      0.78      0.78       238\n",
      "\n",
      "    accuracy                           0.79       863\n",
      "   macro avg       0.73      0.75      0.74       863\n",
      "weighted avg       0.82      0.79      0.81       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", rf.best_params_) \n",
    "print(\"Best Accuracy:\", rf.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        rf.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 149, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_depth': 3, 'clf__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.8122827346465817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.98      0.99      0.99       474\n",
      "     mid-cap       0.51      0.85      0.64       151\n",
      "   small-cap       0.81      0.45      0.58       238\n",
      "\n",
      "    accuracy                           0.82       863\n",
      "   macro avg       0.77      0.76      0.74       863\n",
      "weighted avg       0.85      0.82      0.81       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", et.best_params_) \n",
    "print(\"Best Accuracy:\", et.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        et.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 112, 'clf__learning_rate': 0.9081632653061225, 'clf__base_estimator__min_samples_split': 18, 'clf__base_estimator__min_samples_leaf': 2, 'clf__base_estimator__max_depth': None, 'clf__base_estimator__class_weight': None}\n",
      "Best Accuracy: 0.9602162997296253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       474\n",
      "     mid-cap       0.93      0.92      0.92       151\n",
      "   small-cap       0.95      0.97      0.96       238\n",
      "\n",
      "    accuracy                           0.97       863\n",
      "   macro avg       0.96      0.96      0.96       863\n",
      "weighted avg       0.97      0.97      0.97       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", ada.best_params_) \n",
    "print(\"Best Accuracy:\", ada.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        ada.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 132, 'clf__min_samples_split': 19, 'clf__min_samples_leaf': 2, 'clf__max_depth': 4, 'clf__learning_rate': 0.7244897959183674}\n",
      "Best Accuracy: 0.9729625337968327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.96      0.90      0.93       151\n",
      "   small-cap       0.94      0.97      0.96       238\n",
      "\n",
      "    accuracy                           0.98       863\n",
      "   macro avg       0.97      0.96      0.96       863\n",
      "weighted avg       0.98      0.98      0.98       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", gb.best_params_) \n",
    "print(\"Best Accuracy:\", gb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        gb.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__tree__min_samples_split': 3, 'clf__tree__min_samples_leaf': 5, 'clf__tree__max_depth': 4, 'clf__tree__class_weight': 'balanced', 'clf__gb__n_estimators': 146, 'clf__gb__min_samples_split': 14, 'clf__gb__min_samples_leaf': 7, 'clf__gb__max_depth': 4, 'clf__gb__learning_rate': 0.6510204081632653, 'clf__ada__n_estimators': 68, 'clf__ada__learning_rate': 0.5959183673469388, 'clf__ada__base_estimator__min_samples_split': 9, 'clf__ada__base_estimator__min_samples_leaf': 6, 'clf__ada__base_estimator__max_depth': None, 'clf__ada__base_estimator__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.9636925453843183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.99      1.00      1.00       474\n",
      "     mid-cap       0.94      0.87      0.90       151\n",
      "   small-cap       0.92      0.95      0.94       238\n",
      "\n",
      "    accuracy                           0.96       863\n",
      "   macro avg       0.95      0.94      0.94       863\n",
      "weighted avg       0.96      0.96      0.96       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", vote.best_params_) \n",
    "print(\"Best Accuracy:\", vote.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        vote.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 958, 'clf__max_depth': 3, 'clf__learning_rate': 0.21020408163265308}\n",
      "Best Accuracy: 0.9652375434530707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.94      0.91      0.93       151\n",
      "   small-cap       0.95      0.97      0.96       238\n",
      "\n",
      "    accuracy                           0.97       863\n",
      "   macro avg       0.96      0.96      0.96       863\n",
      "weighted avg       0.97      0.97      0.97       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", xgb.best_params_) \n",
    "print(\"Best Accuracy:\", xgb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        xgb.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__kernel': 'poly', 'clf__gamma': 1.9306977288832496, 'clf__class_weight': 'balanced', 'clf__C': 5.179474679231202}\n",
      "Best Accuracy: 0.9312475859405176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.84      0.85      0.84       151\n",
      "   small-cap       0.90      0.90      0.90       238\n",
      "\n",
      "    accuracy                           0.95       863\n",
      "   macro avg       0.92      0.92      0.92       863\n",
      "weighted avg       0.95      0.95      0.95       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", svm.best_params_) \n",
    "print(\"Best Accuracy:\", svm.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        svm.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__opt_learning_rate': 0.00339322177189533, 'clf__layer_two_neurons': 79, 'clf__layer_two_dropout': 0.5612244897959183, 'clf__layer_one_neurons': 130, 'clf__layer_one_dropout': 0.616326530612245, 'clf__epochs': 6, 'clf__batch_size': 128}\n",
      "Best Accuracy: 0.8455001856655446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.67      0.24      0.35       151\n",
      "   small-cap       0.65      0.92      0.77       238\n",
      "\n",
      "    accuracy                           0.84       863\n",
      "   macro avg       0.77      0.72      0.71       863\n",
      "weighted avg       0.85      0.84      0.82       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", ffnn.best_params_) \n",
    "print(\"Best Accuracy:\", ffnn.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        ffnn.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', LogisticRegression(max_iter=10_000, multi_class='multinomial'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__penalty': ['l2', 'none'],\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__solver': ['newton-cg', 'sag', 'lbfgs']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_l1_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', LogisticRegression(penalty='l1', solver='saga', max_iter=10_000, multi_class='multinomial'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_elasticnet_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', LogisticRegression(penalty='elasticnet', solver='saga', max_iter=10_000, multi_class='multinomial'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__C': np.logspace(-5, 2), \n",
    "        'clf__class_weight': [None, 'balanced'],\n",
    "        'clf__l1_ratio': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', KNeighborsClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__n_neighbors': np.arange(1, 22, 2), \n",
    "        'clf__weights': ['uniform', 'distance'],\n",
    "        'clf__metric': ['euclidean','manhattan']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', BernoulliNB())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__alpha': np.logspace(-5, 2)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', GaussianNB())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__var_smoothing': np.logspace(-9, -4)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', BaggingClassifier(DecisionTreeClassifier()))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "et_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', ExtraTreesClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150),\n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__class_weight': [None, 'balanced', 'balanced_subsample']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier()))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__max_depth': np.arange(1, 5),\n",
    "        'clf__n_estimators': np.arange(1, 150), \n",
    "        'clf__min_samples_split': np.arange(2, 21),\n",
    "        'clf__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vote_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', VotingClassifier([\n",
    "            ('tree', DecisionTreeClassifier()), \n",
    "            ('ada', AdaBoostClassifier(base_estimator=DecisionTreeClassifier())), \n",
    "            ('gb', GradientBoostingClassifier())\n",
    "        ]))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__tree__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__tree__min_samples_split': np.arange(2, 21),\n",
    "        'clf__tree__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__tree__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__base_estimator__max_depth': list(np.arange(1, 5)) + [None],\n",
    "        'clf__ada__base_estimator__min_samples_split': np.arange(2, 21),\n",
    "        'clf__ada__base_estimator__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__ada__base_estimator__class_weight': [None, 'balanced'],\n",
    "        'clf__ada__n_estimators': np.arange(1, 150), \n",
    "        'clf__ada__learning_rate': np.linspace(0.1, 1),\n",
    "        'clf__gb__max_depth': np.arange(1, 5),\n",
    "        'clf__gb__n_estimators': np.arange(1, 150), \n",
    "        'clf__gb__min_samples_split': np.arange(2, 21),\n",
    "        'clf__gb__min_samples_leaf': np.arange(1, 8),\n",
    "        'clf__gb__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', XGBClassifier(objective='multi:softprob'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__max_depth': np.arange(1, 25),\n",
    "        'clf__n_estimators': np.arange(1, 1000), \n",
    "        'clf__learning_rate': np.linspace(0.1, 1)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', SVC(decision_function_shape='ovo'))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'pca__n_components': np.linspace(0.1, 0.9),\n",
    "        'clf__C': np.logspace(-5, 2),\n",
    "        'clf__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'clf__gamma': list(np.logspace(-5, 2)) + ['scale'],\n",
    "        'clf__class_weight': [None, 'balanced']\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ffnn_pca = RandomizedSearchCV(\n",
    "    estimator=Pipeline([\n",
    "        ('ss', ss), \n",
    "        ('pca', PCA()),\n",
    "        ('clf', KerasClassifier(build_fn=ffnn_fn, verbose=0))\n",
    "    ]),\n",
    "    param_distributions={\n",
    "        'clf__layer_one_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_two_neurons': np.arange(10, X_train.shape[1]),\n",
    "        'clf__layer_one_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__layer_two_dropout': np.linspace(0.5, 0.8),\n",
    "        'clf__opt_learning_rate': np.logspace(-4, -1),\n",
    "        'clf__batch_size': [128, 256],\n",
    "        'clf__epochs': np.arange(5, 50)\n",
    "    },\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the models on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 18.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  5.2min finished\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_l1_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              LogisticRegression(C=1.0,\n",
       "                                                                 class_weight=None,\n",
       "                                                                 dual=False,\n",
       "                                                                 fit_intercept...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_elasticnet_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                                   leaf_size=30,\n",
       "                                                                   metric='minkowsk...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              BernoulliNB(alpha=1.0,\n",
       "                                                          binarize=0.0,\n",
       "                                                          class_prior=None,\n",
       "                                                          fit_prior=True)...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              GaussianNB(priors=None,\n",
       "                                                         var_smoothing=1e-09))],\n",
       "                                      verbose=False),\n",
       "                   iid='w...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                                     criterion='gini',\n",
       "                                                                     max_depth...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weigh...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagged_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              RandomForestClassifier(bootstrap=True,\n",
       "                                                                     class_weight=None,\n",
       "                                                                     criterion='...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              ExtraTreesClassifier(bootstrap=False,\n",
       "                                                                   class_weight=None,\n",
       "                                                                   criterion='g...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                                                                 base_estimator=DecisionTreeC...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   28.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                                         init=None,\n",
       "                                                                         learn...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              VotingClassifier(estimators=[('tree',\n",
       "                                                                            DecisionTreeClassifier(class_w...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vote_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              XGBClassifier(base_score=0.5,\n",
       "                                                            booster='gbtree',\n",
       "                                                            colsample_bylevel=1,\n",
       "                                                            c...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.6s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   16.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              SVC(C=1.0, cache_size=200,\n",
       "                                                  class_weight=None, coef0=0.0,\n",
       "                                                  decision_funct...\n",
       "       0.50816327, 0.5244898 , 0.54081633, 0.55714286, 0.57346939,\n",
       "       0.58979592, 0.60612245, 0.62244898, 0.63877551, 0.65510204,\n",
       "       0.67142857, 0.6877551 , 0.70408163, 0.72040816, 0.73673469,\n",
       "       0.75306122, 0.76938776, 0.78571429, 0.80204082, 0.81836735,\n",
       "       0.83469388, 0.85102041, 0.86734694, 0.88367347, 0.9       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pca.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/junkai/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.542857 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "WARNING:tensorflow:Large dropout rate: 0.536735 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('ss',\n",
       "                                              StandardScaler(copy=True,\n",
       "                                                             with_mean=True,\n",
       "                                                             with_std=True)),\n",
       "                                             ('pca',\n",
       "                                              PCA(copy=True,\n",
       "                                                  iterated_power='auto',\n",
       "                                                  n_components=None,\n",
       "                                                  random_state=None,\n",
       "                                                  svd_solver='auto', tol=0.0,\n",
       "                                                  whiten=False)),\n",
       "                                             ('clf',\n",
       "                                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x14f606890>)],...\n",
       "       0.00339322, 0.00390694, 0.00449843, 0.00517947, 0.00596362,\n",
       "       0.00686649, 0.00790604, 0.00910298, 0.01048113, 0.01206793,\n",
       "       0.01389495, 0.01599859, 0.0184207 , 0.02120951, 0.02442053,\n",
       "       0.02811769, 0.03237458, 0.03727594, 0.04291934, 0.04941713,\n",
       "       0.05689866, 0.06551286, 0.0754312 , 0.08685114, 0.1       ])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffnn_pca.fit(X_train, y_train_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__solver': 'lbfgs', 'clf__penalty': 'none', 'clf__class_weight': 'balanced', 'clf__C': 10.0}\n",
      "Best Accuracy: 0.9057551178061027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.65      0.74      0.69       151\n",
      "   small-cap       0.82      0.75      0.78       238\n",
      "\n",
      "    accuracy                           0.89       863\n",
      "   macro avg       0.82      0.83      0.82       863\n",
      "weighted avg       0.89      0.89      0.89       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", lr.best_params_) \n",
    "print(\"Best Accuracy:\", lr.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        lr.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__class_weight': 'balanced', 'clf__C': 1.389495494373136}\n",
      "Best Accuracy: 0.8941676322904596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.65      0.76      0.70       151\n",
      "   small-cap       0.83      0.74      0.78       238\n",
      "\n",
      "    accuracy                           0.89       863\n",
      "   macro avg       0.83      0.83      0.83       863\n",
      "weighted avg       0.89      0.89      0.89       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", lr_l1.best_params_) \n",
    "print(\"Best Accuracy:\", lr_l1.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        lr_l1.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__l1_ratio': 0.9081632653061225, 'clf__class_weight': 'balanced', 'clf__C': 5.179474679231202}\n",
      "Best Accuracy: 0.8941676322904596\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       474\n",
      "     mid-cap       0.63      0.75      0.69       151\n",
      "   small-cap       0.82      0.73      0.78       238\n",
      "\n",
      "    accuracy                           0.88       863\n",
      "   macro avg       0.82      0.83      0.82       863\n",
      "weighted avg       0.89      0.88      0.88       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", lr_elasticnet.best_params_) \n",
    "print(\"Best Accuracy:\", lr_elasticnet.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        lr_elasticnet.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__weights': 'distance', 'clf__n_neighbors': 7, 'clf__metric': 'manhattan'}\n",
      "Best Accuracy: 0.9235225955967555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       474\n",
      "     mid-cap       0.84      0.81      0.83       151\n",
      "   small-cap       0.88      0.91      0.89       238\n",
      "\n",
      "    accuracy                           0.94       863\n",
      "   macro avg       0.91      0.91      0.91       863\n",
      "weighted avg       0.94      0.94      0.94       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", knn.best_params_) \n",
    "print(\"Best Accuracy:\", knn.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        knn.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__alpha': 1e-05}\n",
      "Best Accuracy: 0.8505214368482039\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.58      0.58      0.58       151\n",
      "   small-cap       0.74      0.74      0.74       238\n",
      "\n",
      "    accuracy                           0.85       863\n",
      "   macro avg       0.77      0.77      0.77       863\n",
      "weighted avg       0.85      0.85      0.85       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", bnb.best_params_) \n",
    "print(\"Best Accuracy:\", bnb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        bnb.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__var_smoothing': 7.906043210907701e-05}\n",
      "Best Accuracy: 0.8501351873310158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.65      0.68      0.66       151\n",
      "   small-cap       0.79      0.77      0.78       238\n",
      "\n",
      "    accuracy                           0.88       863\n",
      "   macro avg       0.81      0.81      0.81       863\n",
      "weighted avg       0.88      0.88      0.88       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", gnb.best_params_) \n",
    "print(\"Best Accuracy:\", gnb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        gnb.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__min_samples_split': 7, 'clf__min_samples_leaf': 1, 'clf__max_depth': None, 'clf__class_weight': None}\n",
      "Best Accuracy: 0.8733101583623021\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.96      0.97      0.97       474\n",
      "     mid-cap       0.74      0.72      0.73       151\n",
      "   small-cap       0.83      0.84      0.84       238\n",
      "\n",
      "    accuracy                           0.89       863\n",
      "   macro avg       0.85      0.84      0.85       863\n",
      "weighted avg       0.89      0.89      0.89       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", tree.best_params_) \n",
    "print(\"Best Accuracy:\", tree.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        tree.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 85, 'clf__base_estimator__min_samples_split': 13, 'clf__base_estimator__min_samples_leaf': 1, 'clf__base_estimator__max_depth': 4, 'clf__base_estimator__class_weight': None}\n",
      "Best Accuracy: 0.8427964465044419\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.93      0.95      0.94       474\n",
      "     mid-cap       0.64      0.54      0.58       151\n",
      "   small-cap       0.78      0.82      0.80       238\n",
      "\n",
      "    accuracy                           0.84       863\n",
      "   macro avg       0.78      0.77      0.77       863\n",
      "weighted avg       0.84      0.84      0.84       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", bagged.best_params_) \n",
    "print(\"Best Accuracy:\", bagged.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        bagged.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 60, 'clf__min_samples_split': 6, 'clf__min_samples_leaf': 7, 'clf__max_depth': 4, 'clf__class_weight': 'balanced_subsample'}\n",
      "Best Accuracy: 0.8091927385090769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.96      0.86      0.91       474\n",
      "     mid-cap       0.45      0.62      0.52       151\n",
      "   small-cap       0.79      0.78      0.78       238\n",
      "\n",
      "    accuracy                           0.79       863\n",
      "   macro avg       0.73      0.75      0.74       863\n",
      "weighted avg       0.82      0.79      0.81       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", rf.best_params_) \n",
    "print(\"Best Accuracy:\", rf.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        rf.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 149, 'clf__min_samples_split': 10, 'clf__min_samples_leaf': 1, 'clf__max_depth': 3, 'clf__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.8122827346465817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.98      0.99      0.99       474\n",
      "     mid-cap       0.51      0.85      0.64       151\n",
      "   small-cap       0.81      0.45      0.58       238\n",
      "\n",
      "    accuracy                           0.82       863\n",
      "   macro avg       0.77      0.76      0.74       863\n",
      "weighted avg       0.85      0.82      0.81       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", et.best_params_) \n",
    "print(\"Best Accuracy:\", et.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        et.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 112, 'clf__learning_rate': 0.9081632653061225, 'clf__base_estimator__min_samples_split': 18, 'clf__base_estimator__min_samples_leaf': 2, 'clf__base_estimator__max_depth': None, 'clf__base_estimator__class_weight': None}\n",
      "Best Accuracy: 0.9602162997296253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      0.99      1.00       474\n",
      "     mid-cap       0.93      0.92      0.92       151\n",
      "   small-cap       0.95      0.97      0.96       238\n",
      "\n",
      "    accuracy                           0.97       863\n",
      "   macro avg       0.96      0.96      0.96       863\n",
      "weighted avg       0.97      0.97      0.97       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", ada.best_params_) \n",
    "print(\"Best Accuracy:\", ada.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test, \n",
    "        ada.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 132, 'clf__min_samples_split': 19, 'clf__min_samples_leaf': 2, 'clf__max_depth': 4, 'clf__learning_rate': 0.7244897959183674}\n",
      "Best Accuracy: 0.9729625337968327\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.96      0.90      0.93       151\n",
      "   small-cap       0.94      0.97      0.96       238\n",
      "\n",
      "    accuracy                           0.98       863\n",
      "   macro avg       0.97      0.96      0.96       863\n",
      "weighted avg       0.98      0.98      0.98       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", gb.best_params_) \n",
    "print(\"Best Accuracy:\", gb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        gb.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__tree__min_samples_split': 3, 'clf__tree__min_samples_leaf': 5, 'clf__tree__max_depth': 4, 'clf__tree__class_weight': 'balanced', 'clf__gb__n_estimators': 146, 'clf__gb__min_samples_split': 14, 'clf__gb__min_samples_leaf': 7, 'clf__gb__max_depth': 4, 'clf__gb__learning_rate': 0.6510204081632653, 'clf__ada__n_estimators': 68, 'clf__ada__learning_rate': 0.5959183673469388, 'clf__ada__base_estimator__min_samples_split': 9, 'clf__ada__base_estimator__min_samples_leaf': 6, 'clf__ada__base_estimator__max_depth': None, 'clf__ada__base_estimator__class_weight': 'balanced'}\n",
      "Best Accuracy: 0.9636925453843183\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       0.99      1.00      1.00       474\n",
      "     mid-cap       0.94      0.87      0.90       151\n",
      "   small-cap       0.92      0.95      0.94       238\n",
      "\n",
      "    accuracy                           0.96       863\n",
      "   macro avg       0.95      0.94      0.94       863\n",
      "weighted avg       0.96      0.96      0.96       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", vote.best_params_) \n",
    "print(\"Best Accuracy:\", vote.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        vote.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__n_estimators': 958, 'clf__max_depth': 3, 'clf__learning_rate': 0.21020408163265308}\n",
      "Best Accuracy: 0.9652375434530707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.94      0.91      0.93       151\n",
      "   small-cap       0.95      0.97      0.96       238\n",
      "\n",
      "    accuracy                           0.97       863\n",
      "   macro avg       0.96      0.96      0.96       863\n",
      "weighted avg       0.97      0.97      0.97       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", xgb.best_params_) \n",
    "print(\"Best Accuracy:\", xgb.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        xgb.predict(X_test), \n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__kernel': 'poly', 'clf__gamma': 1.9306977288832496, 'clf__class_weight': 'balanced', 'clf__C': 5.179474679231202}\n",
      "Best Accuracy: 0.9312475859405176\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.84      0.85      0.84       151\n",
      "   small-cap       0.90      0.90      0.90       238\n",
      "\n",
      "    accuracy                           0.95       863\n",
      "   macro avg       0.92      0.92      0.92       863\n",
      "weighted avg       0.95      0.95      0.95       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", svm.best_params_) \n",
    "print(\"Best Accuracy:\", svm.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        svm.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Combination Of Hyperparameters: {'clf__opt_learning_rate': 0.00339322177189533, 'clf__layer_two_neurons': 79, 'clf__layer_two_dropout': 0.5612244897959183, 'clf__layer_one_neurons': 130, 'clf__layer_one_dropout': 0.616326530612245, 'clf__epochs': 6, 'clf__batch_size': 128}\n",
      "Best Accuracy: 0.8455001856655446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   large-cap       1.00      1.00      1.00       474\n",
      "     mid-cap       0.67      0.24      0.35       151\n",
      "   small-cap       0.65      0.92      0.77       238\n",
      "\n",
      "    accuracy                           0.84       863\n",
      "   macro avg       0.77      0.72      0.71       863\n",
      "weighted avg       0.85      0.84      0.82       863\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Combination Of Hyperparameters:\", ffnn.best_params_) \n",
    "print(\"Best Accuracy:\", ffnn.best_score_)\n",
    "print(\n",
    "    classification_report(\n",
    "        y_test,\n",
    "        ffnn.predict(X_test),\n",
    "        target_names=['large-cap', 'mid-cap', 'small-cap']\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
